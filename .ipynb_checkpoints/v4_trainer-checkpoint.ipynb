{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "661e7371-4255-4a8f-a377-2ec87c35d6f9",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Trainer v4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e1abc7af-0ef6-4d26-be03-1d4ccdc8fadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/python\n",
    "import sys, getopt, os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\" # or any {'0', '1', '2','3'}\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from lib.lib_utils import utilities\n",
    "from lib.lib_logger import logger\n",
    "from lib.lib_keras import keras_applications\n",
    "from lib.lib_dataset import Dataset\n",
    "from lib.lib_plot import show_training_performance,show_dataset_chart"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9200413-87be-4ac0-b66b-82d71d1a7295",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Definitions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ca235d0d-e83c-4766-8d3b-1852a0f0b85b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(base,num_of_classes,model_name):\n",
    "    #biasInitializer = tf.keras.initializers.HeNormal(seed=101)\n",
    "    inputShape=base_model.input_shape\n",
    "    inputShape=(inputShape[1],inputShape[2],inputShape[3])\n",
    "    inputs = keras.Input(shape=inputShape)\n",
    "    x = base(inputs, training=True)## todo\n",
    "    #x = keras.layers.Conv2D(1280*2, (3, 3), strides= (1, 1), activation=\"relu\", name=\"for_CAM\")(x)\n",
    "    x = keras.layers.GlobalAveragePooling2D()(x)\n",
    "    x = keras.layers.Dense(num_of_classes)(x)\n",
    "    outputs = keras.layers.Softmax()(x)\n",
    "    model=keras.Model(inputs, outputs,name=model_name)\n",
    "    return model\n",
    "\n",
    "def print_summary(x):\n",
    "    log_txt.print_log(\"\\t\"+x,print_on_screen=True)\n",
    "    #print(\"\\t\"+x)\n",
    "    x=str(x)\n",
    "    if x.startswith(\"Total params:\") or x.startswith(\"Trainable params:\") or x.startswith(\"Non-trainable params:\"):\n",
    "        token=x.split(':')\n",
    "        k=token[0]\n",
    "        v=token[1].strip()\n",
    "        _data[k]=v"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced65b35-390b-4775-b29f-4b60d1db9036",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f452101d-9656-4117-9d2b-d7f7dd222e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    util=utilities()\n",
    "  \n",
    "    try:\n",
    "        opts, args = getopt.getopt(argv,\"hi:\",[\"ifile=\",\"ofile=\"])\n",
    "        \n",
    "    except getopt.GetoptError:\n",
    "        print ('train.py -i <inputfile>')\n",
    "        sys.exit(2)\n",
    "        \n",
    "    for opt, arg in opts:\n",
    "        if opt == '-h':\n",
    "            print ('train.py -i <conf_yourFilename.json>')\n",
    "            sys.exit()\n",
    "        elif opt in (\"-i\", \"--ifile\"):\n",
    "            inputfile = arg\n",
    "\n",
    "    print ('Input file is \"', inputfile)\n",
    "    USER_PARA=util.load_JSON_file('my_workspace/exp00_montgomeryset.json')\n",
    "    #USER_PARA=util.load_JSON_file('my_workspace/exp01_covid19_mobilenetv2.json')\n",
    "    #USER_PARA=util.load_JSON_file(inputfile)\n",
    "    \n",
    "    # step: Definitions\n",
    "    prefix=USER_PARA['prefix']\n",
    "    project_workspace=os.path.join('my_workspace',prefix)\n",
    "\n",
    "    color_mode=USER_PARA[\"colorMode\"]\n",
    "    imgChannel= 1 if color_mode=='grayscale' else 3\n",
    "    image_size=(USER_PARA['imgHeight'],USER_PARA['imgWidth'])\n",
    "\n",
    "    image_shape=(USER_PARA['imgHeight'],USER_PARA['imgWidth'],imgChannel)\n",
    "\n",
    "    logFilenameJSON=os.path.join(project_workspace,\"log.json\")\n",
    "    logFilenameTXT=os.path.join(project_workspace,\"log.txt\")\n",
    "\n",
    "    base_architecture=USER_PARA['architecture']\n",
    "\n",
    "    root_dataset=USER_PARA[\"root_dataset\"]\n",
    "\n",
    "    batch_size=USER_PARA[\"batch_size\"]\n",
    "    dataset_tag=USER_PARA['dataset_tag']\n",
    "    epochs=USER_PARA['epochs']\n",
    "\n",
    "    callbacks_enabled={\"CSVLogger\":True,\n",
    "                         \"TensorBoard\":True,\n",
    "                         \"ModelCheckpoint\":True,\n",
    "                         \"EarlyStopping\":True,\n",
    "                         \"TerminateOnNaN\":True,\n",
    "                         \"ReduceLROnPlateau\":True,\n",
    "                         \"LearningRateScheduler\":False,\n",
    "                         \"RemoteMonitor\":False}\n",
    "    _exception={}            \n",
    "    \n",
    "    \n",
    "    # step: directory structure and filenames\n",
    "    if not os.path.isdir(project_workspace):\n",
    "        os.mkdir(project_workspace)\n",
    "\n",
    "    path_to_image=os.path.join(project_workspace,'image')\n",
    "    if not os.path.isdir(path_to_image):\n",
    "        os.mkdir(path_to_image)\n",
    "\n",
    "    log_json=logger(logFilenameJSON)\n",
    "    log_txt=logger(logFilenameTXT)\n",
    "\n",
    "    log_txt.print_log(\"Getting Starting...\",overwrite=True)\n",
    "    log_txt.print_log('\\tprefix:'+prefix)\n",
    "\n",
    "    log_json.print_jsonlog({'prefix':prefix},overwrite=True)\n",
    "    \n",
    "    # step: Dataset\n",
    "    log_txt.print_log('Loading Dataset...')\n",
    "    datasetOBJ=Dataset(dataset_tag=dataset_tag,\n",
    "                 path_to_dataset=root_dataset,\n",
    "                 image_size=image_size, \n",
    "                 color_mode=color_mode, \n",
    "                 batch_size=batch_size\n",
    "                )\n",
    "    (x_train, y_train), (x_valid, y_valid)=datasetOBJ.load_dataset()\n",
    "    num_of_classes=x_train.num_classes\n",
    "    \n",
    "    trainset_dict=datasetOBJ.as_dictionary(x_train)\n",
    "    validset_dict=datasetOBJ.as_dictionary(x_valid)\n",
    "    #show_chart(chart_Type=\"barh\", data_Dictionary=trainset_dict,chart_title='Training Set',label_x='classes',label_y=\"samples\") \n",
    "    #show_chart(chart_Type=\"barh\", data_Dictionary=trainset_dict,chart_title='Training Set',label_x='classes',label_y=\"samples\") \n",
    "    dataset_distribution=os.path.join(project_workspace,'image','dataset_distribution.png')\n",
    "    show_dataset_chart(trainset_dict,validset_dict,save_filename=dataset_distribution,show_legend=True )\n",
    "    \n",
    "    _data={        \n",
    "        \"dataset\":{\n",
    "            \"trainset\":{\"num_classes\":x_train.num_classes,\n",
    "                        \"num_samples\":x_train.samples,\n",
    "                        \"class_wise_count\":datasetOBJ.trainSet_as_dictionary()\n",
    "                      },\n",
    "            \"validateset\":{\"num_classes\":x_valid.num_classes,\n",
    "                        \"num_samples\":x_valid.samples,\n",
    "                        \"class_wise_count\":datasetOBJ.validateSet_as_dictionary()\n",
    "                      }        \n",
    "            }\n",
    "        }\n",
    "\n",
    "    _d1=f'\\tTrainSet: Found {_data[\"dataset\"][\"trainset\"][\"num_samples\"]} images belonging to {_data[\"dataset\"][\"trainset\"][\"num_classes\"]} classes.'\n",
    "    _d2=f'\\tValidateset: Found {_data[\"dataset\"][\"validateset\"][\"num_samples\"]} images belonging to {_data[\"dataset\"][\"validateset\"][\"num_classes\"]} classes.'\n",
    "\n",
    "    log_txt.print_log(_d1,print_on_screen=False)\n",
    "    log_txt.print_log(_d2,print_on_screen=False)\n",
    "    log_json.print_jsonlog(_data)\n",
    "    \n",
    "\n",
    "    # step: Modeling\n",
    "    keras_app=keras_applications()\n",
    "    base_model=keras_app.get_base_model(base_architecture)\n",
    "\n",
    "    log_txt.print_log(\"Modeling...\")\n",
    "    log_txt.print_log(\"\\tbase_model: \"+ base_architecture)\n",
    "    \n",
    "    ## create model\n",
    "    model=create_model(base=base_model,\n",
    "                   num_of_classes=num_of_classes,\n",
    "                   model_name=prefix)\n",
    "    \n",
    "    _data={}\n",
    "    model.summary(print_fn=print_summary)\n",
    "    _data={\"model\":{\"base_model\":base_architecture,\n",
    "                    \"summary\":_data\n",
    "                   }\n",
    "    }\n",
    "    log_json.print_jsonlog(_data)\n",
    "\n",
    "    model_snap=os.path.join(project_workspace,'image','model_snap.png')\n",
    "    keras.utils.plot_model(model,\n",
    "                           to_file=model_snap,\n",
    "                           show_shapes=True,\n",
    "                           show_dtype=False,\n",
    "                           show_layer_names=True,\n",
    "                           rankdir='TB',\n",
    "                           expand_nested=False,\n",
    "                           dpi=96)    \n",
    "        \n",
    "    #callbacks\n",
    "    # https://blog.paperspace.com/tensorflow-callbacks/\n",
    "    path_csvname = os.path.join (project_workspace,\"CSVLogger.csv\")\n",
    "    path_checkpoint = os.path.join(project_workspace,'ckpt','model_epoch{epoch:02d}_vLoss{val_loss:.2f}.hdf5')\n",
    "    path_custom_file1 = os.path.join (project_workspace,\"log_batchwise.txt\")\n",
    "\n",
    "    path_tensorboardLog = os.path.join (project_workspace,\"tensorboard_logs\")\n",
    "    #path_tensorboardLog = os.path.join (project_workspace,'tensorboard_logs',\"scalars\" , datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n",
    "\n",
    "\n",
    "    CSVLogger_cb = tf.keras.callbacks.CSVLogger(path_csvname, \n",
    "                                 separator=',', \n",
    "                                 append=True)\n",
    "\n",
    "\n",
    "    TensorBoard_cb = tf.keras.callbacks.TensorBoard(log_dir=path_tensorboardLog,\n",
    "                                              histogram_freq=1,\n",
    "                                              write_graph=True,\n",
    "                                              write_images=True,\n",
    "                                              update_freq=batch_size,\n",
    "                                              #write_steps_per_second=False,\n",
    "                                              profile_batch=2,\n",
    "                                              embeddings_metadata=None)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ModelCheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                                    save_best_only=True, ###to save space\n",
    "                                                    save_weights_only=False,\n",
    "                                                    monitor='val_accuracy',\n",
    "                                                    mode='max')\n",
    "\n",
    "\n",
    "\n",
    "    EarlyStopping_cb = tf.keras.callbacks.EarlyStopping(monitor='val_loss', \n",
    "                                                       min_delta=0.001,\n",
    "                                                       patience=4,\n",
    "                                                       verbose=0, \n",
    "                                                       mode='auto',\n",
    "                                                       baseline=None,\n",
    "                                                       restore_best_weights=False)\n",
    "\n",
    "    TerminateOnNaN_cb = tf.keras.callbacks.TerminateOnNaN()\n",
    "\n",
    "    ReduceLROnPlateau_cb = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss',\n",
    "                                                                factor=0.01,\n",
    "                                                                patience=3,\n",
    "                                                                verbose=0,\n",
    "                                                                mode='auto',\n",
    "                                                                min_delta=0.001,\n",
    "                                                                cooldown=0,\n",
    "                                                                min_lr=0)\n",
    "\n",
    "    def scheduler(epoch, lr):\n",
    "        if epoch < 15:\n",
    "            return lr\n",
    "        else:\n",
    "            return lr * tf.math.exp(-0.0001)\n",
    "\n",
    "    LearningRateScheduler_cb = tf.keras.callbacks.LearningRateScheduler(scheduler, \n",
    "                                                                        verbose=0)\n",
    "\n",
    "\n",
    "\n",
    "    RemoteMonitor_cb = tf.keras.callbacks.RemoteMonitor(root='http://localhost:9000',\n",
    "                                                        path='/publish/epoch/end/',\n",
    "                                                        field='data',\n",
    "                                                        headers=None,\n",
    "                                                        send_as_json=False)\n",
    "\n",
    "\n",
    "    callback_dictionary={\"CSVLogger\":{\"callback\":CSVLogger_cb},\n",
    "                         \"TensorBoard\":{\"callback\":TensorBoard_cb},\n",
    "                         \"ModelCheckpoint\":{\"callback\":ModelCheckpoint_cb},\n",
    "                         \"EarlyStopping\":{\"callback\":EarlyStopping_cb},\n",
    "                         \"TerminateOnNaN\":{\"callback\":TerminateOnNaN_cb},\n",
    "                         \"ReduceLROnPlateau\":{\"callback\":ReduceLROnPlateau_cb},\n",
    "                         \"LearningRateScheduler\":{\"callback\":LearningRateScheduler_cb},\n",
    "                         \"RemoteMonitor\":{\"callback\":RemoteMonitor_cb}}\n",
    "    callbacksList=[]\n",
    "    for k in callbacks_enabled:\n",
    "        if callbacks_enabled[k]:\n",
    "            callbacksList.append(callback_dictionary[k][\"callback\"])\n",
    "\n",
    "    # step: training\n",
    "    historyIndex=0\n",
    "    index_finish=0\n",
    "\n",
    "    steps=epochs\n",
    "    _metrics=['MeanSquaredError','AUC','Precision','Recall','accuracy']\n",
    "    histories={}\n",
    "    _data={\"training\":{}}\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=keras.optimizers.Adam(),\n",
    "        loss=keras.losses.CategoricalCrossentropy(),\n",
    "        metrics=_metrics,\n",
    "        loss_weights=None,\n",
    "        weighted_metrics=None,\n",
    "        run_eagerly=None,\n",
    "        steps_per_execution=None\n",
    "    )\n",
    "    class_weight_dict=None\n",
    "\n",
    "    _data_compile={\"optimizer\":\"adam\",\n",
    "                   \"loss\":\"CategoricalCrossentropy\",\n",
    "                   \"metrics\":[\"accuracy\"],\n",
    "                   \"loss_weights\":\"None\",\n",
    "                   \"weighted_metrics\":\"None\"\n",
    "                  }\n",
    "\n",
    "    log_txt.print_log(\"Training...\")\n",
    "    log_txt.print_log(\"\\tcompile:\")\n",
    "    log_txt.print_log(\"\\t\\toptimizer: \"+_data_compile[\"optimizer\"])\n",
    "    log_txt.print_log(\"\\t\\tloss: \"+_data_compile[\"loss\"])\n",
    "    log_txt.print_log(\"\\t\\tloss_weights: \"+_data_compile[\"loss_weights\"])   \n",
    "    log_txt.print_log(\"\\t\\tweighted_metrics: \"+_data_compile[\"weighted_metrics\"])     \n",
    "    \n",
    "    index_start=index_finish\n",
    "    index_finish+=steps\n",
    "    historyIndex+=1\n",
    "    _data={\"training\":{}}\n",
    "    _data_epoch={\"index\":historyIndex,\n",
    "                 \"epoch_from\":index_start,\n",
    "                 \"epoch_to\":index_finish\n",
    "                }\n",
    "    _data[\"training\"][\"session\"]=_data_epoch\n",
    "    _data[\"training\"][\"compiler\"]=_data_compile\n",
    "\n",
    "    log_txt.print_log(\"\\tsession:\")\n",
    "    log_txt.print_log(f\"\\t\\tindex:{historyIndex}, epoch from {index_start} to {index_finish}\")\n",
    "    log_json.print_jsonlog(_data)\n",
    "\n",
    "    try:\n",
    "        train_session = model.fit(\n",
    "            x=x_train,\n",
    "            #y=y_train,\n",
    "            #validation_split=0.0,\n",
    "            validation_data=(x_valid),\n",
    "            batch_size=batch_size,\n",
    "            epochs=index_finish,\n",
    "            callbacks=callbacksList,\n",
    "            verbose=1,\n",
    "            shuffle=True,\n",
    "            class_weight=class_weight_dict,\n",
    "            sample_weight=None,\n",
    "            initial_epoch=index_start,\n",
    "            steps_per_epoch=None,\n",
    "            validation_steps=None,\n",
    "            validation_batch_size=None,\n",
    "            validation_freq=1,\n",
    "            max_queue_size=10,\n",
    "            workers=1,\n",
    "            use_multiprocessing=False)\n",
    "\n",
    "        #histories[historyIndex]=train_session.history\n",
    "        log_txt.print_log(\"\\tresults:\",print_on_screen=False)\n",
    "        log_txt.print_log(str(train_session.history),print_on_screen=False)\n",
    "\n",
    "        if len(train_session.epoch)<index_finish-index_start:\n",
    "            log_txt.print_log('\\tTraining session completed at epoch '+str(len(train_session.epoch)))\n",
    "            _data={\"stopped_at_epoch\":len(train_session.epoch)}\n",
    "            log_json.print_jsonlog(_data)\n",
    "\n",
    "        training_performance = os.path.join (path_to_image,\"training_performance.png\")\n",
    "        show_training_performance(path_csvname=path_csvname,save_filename=training_performance)\n",
    "\n",
    "    except Exception as e:\n",
    "        if e.error_code==8:\n",
    "            _exception={\"error\":\n",
    "                        {\"code\":e.error_code,\n",
    "                         \"desc\":\"Resource exhausted\",\n",
    "                         \"fix\":[\"reduce batch size\"]\n",
    "                        }\n",
    "                       }\n",
    "        else:\n",
    "            _exception={\"error\":\n",
    "                        {\"code\":e.error_code,\n",
    "                         \"desc\":str(e),\n",
    "                        }\n",
    "                       }\n",
    "\n",
    "        log_txt.print_log(str(_exception))\n",
    "        log_json.print_jsonlog(_exception)    \n",
    "        \n",
    "    # step: Save the model\n",
    "    fname = os.path.join (project_workspace,\"saved_model\")\n",
    "    savedModel = os.path.join(project_workspace, \"saved_model\")\n",
    "    savedWeights = os.path.join(project_workspace,\"saved_weights\",\"weights\")\n",
    "\n",
    "\n",
    "    log_txt.print_log(\"Saving...\")\n",
    "    model.save(savedModel)\n",
    "    log_txt.print_log(\"\\tComplete model saved:\"+ str(savedModel))\n",
    "    model.save_weights(savedWeights)\n",
    "    log_txt.print_log(\"\\tWeights saved:\"+ str(savedWeights))\n",
    "\n",
    "    _data={\"saved\":{\"full\":str(savedModel),\n",
    "                  \"weights\":str(savedWeights)}}\n",
    "    log_json.print_jsonlog(_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f3177bbe-826d-4f2a-94ea-e15bd8130e71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.py -i <inputfile>\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGetoptError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m----> 5\u001b[0m     opts, args \u001b[38;5;241m=\u001b[39m \u001b[43mgetopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetopt\u001b[49m\u001b[43m(\u001b[49m\u001b[43margv\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhi:\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mifile=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mofile=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m getopt\u001b[38;5;241m.\u001b[39mGetoptError:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/getopt.py:95\u001b[0m, in \u001b[0;36mgetopt\u001b[0;34m(args, shortopts, longopts)\u001b[0m\n\u001b[1;32m     94\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 95\u001b[0m         opts, args \u001b[38;5;241m=\u001b[39m \u001b[43mdo_shorts\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshortopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m opts, args\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/getopt.py:195\u001b[0m, in \u001b[0;36mdo_shorts\u001b[0;34m(opts, optstring, shortopts, args)\u001b[0m\n\u001b[1;32m    194\u001b[0m opt, optstring \u001b[38;5;241m=\u001b[39m optstring[\u001b[38;5;241m0\u001b[39m], optstring[\u001b[38;5;241m1\u001b[39m:]\n\u001b[0;32m--> 195\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mshort_has_arg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshortopts\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m    196\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m optstring \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/getopt.py:211\u001b[0m, in \u001b[0;36mshort_has_arg\u001b[0;34m(opt, shortopts)\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m shortopts\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m:\u001b[39m\u001b[38;5;124m'\u001b[39m, i\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m--> 211\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m GetoptError(_(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moption -\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m not recognized\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;241m%\u001b[39m opt, opt)\n",
      "\u001b[0;31mGetoptError\u001b[0m: option -f not recognized",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mSystemExit\u001b[0m                                Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m----> 2\u001b[0m     \u001b[43mmain\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margv\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36mmain\u001b[0;34m(argv)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[38;5;28mprint\u001b[39m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain.py -i <inputfile>\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     \u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m opt, arg \u001b[38;5;129;01min\u001b[39;00m opts:\n",
      "\u001b[0;31mSystemExit\u001b[0m: 2",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "    \u001b[0;31m[... skipping hidden 1 frame]\u001b[0m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/IPython/core/interactiveshell.py:1972\u001b[0m, in \u001b[0;36mInteractiveShell.showtraceback\u001b[0;34m(self, exc_tuple, filename, tb_offset, exception_only, running_compiled_code)\u001b[0m\n\u001b[1;32m   1969\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m exception_only:\n\u001b[1;32m   1970\u001b[0m     stb \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAn exception has occurred, use \u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mtb to see \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   1971\u001b[0m            \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mthe full traceback.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m-> 1972\u001b[0m     stb\u001b[38;5;241m.\u001b[39mextend(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mInteractiveTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_exception_only\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1973\u001b[0m \u001b[43m                                                     \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1974\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1975\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1976\u001b[0m         \u001b[38;5;66;03m# Exception classes can customise their traceback - we\u001b[39;00m\n\u001b[1;32m   1977\u001b[0m         \u001b[38;5;66;03m# use this in IPython.parallel for exceptions occurring\u001b[39;00m\n\u001b[1;32m   1978\u001b[0m         \u001b[38;5;66;03m# in the engines. This should return a list of strings.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/IPython/core/ultratb.py:585\u001b[0m, in \u001b[0;36mListTB.get_exception_only\u001b[0;34m(self, etype, value)\u001b[0m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_exception_only\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype, value):\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;124;03m\"\"\"Only print the exception type and message, without a traceback.\u001b[39;00m\n\u001b[1;32m    579\u001b[0m \n\u001b[1;32m    580\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    583\u001b[0m \u001b[38;5;124;03m    value : exception value\u001b[39;00m\n\u001b[1;32m    584\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 585\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mListTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/IPython/core/ultratb.py:443\u001b[0m, in \u001b[0;36mListTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, context)\u001b[0m\n\u001b[1;32m    440\u001b[0m     chained_exc_ids\u001b[38;5;241m.\u001b[39madd(\u001b[38;5;28mid\u001b[39m(exception[\u001b[38;5;241m1\u001b[39m]))\n\u001b[1;32m    441\u001b[0m     chained_exceptions_tb_offset \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m    442\u001b[0m     out_list \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 443\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    444\u001b[0m \u001b[43m            \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchained_exc_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    445\u001b[0m \u001b[43m            \u001b[49m\u001b[43mchained_exceptions_tb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    446\u001b[0m         \u001b[38;5;241m+\u001b[39m chained_exception_message\n\u001b[1;32m    447\u001b[0m         \u001b[38;5;241m+\u001b[39m out_list)\n\u001b[1;32m    449\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out_list\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/IPython/core/ultratb.py:1118\u001b[0m, in \u001b[0;36mAutoFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1116\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1117\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtb \u001b[38;5;241m=\u001b[39m tb\n\u001b[0;32m-> 1118\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mFormattedTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1119\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/IPython/core/ultratb.py:1012\u001b[0m, in \u001b[0;36mFormattedTB.structured_traceback\u001b[0;34m(self, etype, value, tb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m   1009\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode\n\u001b[1;32m   1010\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose_modes:\n\u001b[1;32m   1011\u001b[0m     \u001b[38;5;66;03m# Verbose modes need a full traceback\u001b[39;00m\n\u001b[0;32m-> 1012\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVerboseTB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstructured_traceback\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1013\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\n\u001b[1;32m   1014\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1015\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMinimal\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m   1016\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ListTB\u001b[38;5;241m.\u001b[39mget_exception_only(\u001b[38;5;28mself\u001b[39m, etype, value)\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/IPython/core/ultratb.py:865\u001b[0m, in \u001b[0;36mVerboseTB.structured_traceback\u001b[0;34m(self, etype, evalue, etb, tb_offset, number_of_lines_of_context)\u001b[0m\n\u001b[1;32m    856\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstructured_traceback\u001b[39m(\n\u001b[1;32m    857\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    858\u001b[0m     etype: \u001b[38;5;28mtype\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    862\u001b[0m     number_of_lines_of_context: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m,\n\u001b[1;32m    863\u001b[0m ):\n\u001b[1;32m    864\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a nice text document describing the traceback.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 865\u001b[0m     formatted_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat_exception_as_a_whole\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mevalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    866\u001b[0m \u001b[43m                                                           \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    868\u001b[0m     colors \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mColors  \u001b[38;5;66;03m# just a shorthand + quicker name lookup\u001b[39;00m\n\u001b[1;32m    869\u001b[0m     colorsnormal \u001b[38;5;241m=\u001b[39m colors\u001b[38;5;241m.\u001b[39mNormal  \u001b[38;5;66;03m# used a lot\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/IPython/core/ultratb.py:799\u001b[0m, in \u001b[0;36mVerboseTB.format_exception_as_a_whole\u001b[0;34m(self, etype, evalue, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    796\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(tb_offset, \u001b[38;5;28mint\u001b[39m)\n\u001b[1;32m    797\u001b[0m head \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_header(etype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlong_header)\n\u001b[1;32m    798\u001b[0m records \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 799\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_records\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnumber_of_lines_of_context\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtb_offset\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m etb \u001b[38;5;28;01melse\u001b[39;00m []\n\u001b[1;32m    800\u001b[0m )\n\u001b[1;32m    802\u001b[0m frames \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    803\u001b[0m skipped \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/IPython/core/ultratb.py:854\u001b[0m, in \u001b[0;36mVerboseTB.get_records\u001b[0;34m(self, etb, number_of_lines_of_context, tb_offset)\u001b[0m\n\u001b[1;32m    848\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    849\u001b[0m options \u001b[38;5;241m=\u001b[39m stack_data\u001b[38;5;241m.\u001b[39mOptions(\n\u001b[1;32m    850\u001b[0m     before\u001b[38;5;241m=\u001b[39mbefore,\n\u001b[1;32m    851\u001b[0m     after\u001b[38;5;241m=\u001b[39mafter,\n\u001b[1;32m    852\u001b[0m     pygments_formatter\u001b[38;5;241m=\u001b[39mformatter,\n\u001b[1;32m    853\u001b[0m )\n\u001b[0;32m--> 854\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mstack_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameInfo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43metb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m[tb_offset:]\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/stack_data/core.py:546\u001b[0m, in \u001b[0;36mFrameInfo.stack_data\u001b[0;34m(cls, frame_or_tb, options, collapse_repeated_frames)\u001b[0m\n\u001b[1;32m    530\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m    531\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack_data\u001b[39m(\n\u001b[1;32m    532\u001b[0m         \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    536\u001b[0m         collapse_repeated_frames: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    537\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Iterator[Union[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFrameInfo\u001b[39m\u001b[38;5;124m'\u001b[39m, RepeatedFrames]]:\n\u001b[1;32m    538\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m    An iterator of FrameInfo and RepeatedFrames objects representing\u001b[39;00m\n\u001b[1;32m    540\u001b[0m \u001b[38;5;124;03m    a full traceback or stack. Similar consecutive frames are collapsed into RepeatedFrames\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    544\u001b[0m \u001b[38;5;124;03m    and optionally an Options object to configure.\u001b[39;00m\n\u001b[1;32m    545\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 546\u001b[0m     stack \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miter_stack\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;66;03m# Reverse the stack from a frame so that it's in the same order\u001b[39;00m\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;66;03m# as the order from a traceback, which is the order of a printed\u001b[39;00m\n\u001b[1;32m    550\u001b[0m     \u001b[38;5;66;03m# traceback when read top to bottom (most recent call last)\u001b[39;00m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_frame(frame_or_tb):\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/stack_data/utils.py:98\u001b[0m, in \u001b[0;36miter_stack\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m frame_or_tb:\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m frame_or_tb\n\u001b[0;32m---> 98\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_frame\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[1;32m     99\u001b[0m         frame_or_tb \u001b[38;5;241m=\u001b[39m frame_or_tb\u001b[38;5;241m.\u001b[39mf_back\n\u001b[1;32m    100\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/stack_data/utils.py:91\u001b[0m, in \u001b[0;36mis_frame\u001b[0;34m(frame_or_tb)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_frame\u001b[39m(frame_or_tb: Union[FrameType, TracebackType]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[0;32m---> 91\u001b[0m     \u001b[43massert_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mframe_or_tb\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFrameType\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtypes\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTracebackType\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(frame_or_tb, (types\u001b[38;5;241m.\u001b[39mFrameType,))\n",
      "File \u001b[0;32m~/anaconda3/envs/tfgpu/lib/python3.9/site-packages/stack_data/utils.py:172\u001b[0m, in \u001b[0;36massert_\u001b[0;34m(condition, error)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(error, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    171\u001b[0m     error \u001b[38;5;241m=\u001b[39m \u001b[38;5;167;01mAssertionError\u001b[39;00m(error)\n\u001b[0;32m--> 172\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m error\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(sys.argv[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754341f7-3313-474d-84c2-fac2cba10d14",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
